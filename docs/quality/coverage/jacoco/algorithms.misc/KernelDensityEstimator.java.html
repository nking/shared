<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KernelDensityEstimator.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Jacoco Report</a> &gt; <a href="index.source.html" class="el_package">algorithms.misc</a> &gt; <span class="el_source">KernelDensityEstimator.java</span></div><h1>KernelDensityEstimator.java</h1><pre class="source lang-java linenums">package algorithms.misc;

import algorithms.imageProcessing.FFTUtil;
import algorithms.matrix.MatrixUtil;

import java.util.Arrays;

/**
 * TODO: consider implementing the Improved Sheather - Jones algorithm for estimating bandwidth:.
 * can see implementations
 * https://github.com/tommyod/KDEpy/blob/master/KDEpy/bw_selection.py
 * and
 * https://kdepy.readthedocs.io/en/latest/_modules/KDEpy/FFTKDE.html#FFTKDE
 *
 * TODO: consider implementing
 * &quot;Fast and Accurate Gaussian Kernel Density Estimation&quot;, Jeffrey Heer, University of Washiington.
 * https://idl.cs.washington.edu/files/2021-FastKDE-VIS.pdf
 *
 * TODO: consider using MSER in a 2-D KDE estimator
 *
 * TODO: explore https://github.com/TasCL/cpda/ one day.
 * Probability Density Approximation.
 * The authors are Yi-Shin Lin yishin.lin@utas.edu.au, Andrew Heathcote, William Holmes
 * The repository implements some of
 * Holmes, W. (2015). A practical guide to the Probability Density Approximation (PDA) with improved implementation
 * and error characterization. Journal of Mathematical Psychology, 68-69, 13--24, doi:
 * http://dx.doi.org/10.1016/j.jmp.2015.08.006.
 */
<span class="pc" id="L29">public class KernelDensityEstimator {</span>

    final static double BIG = 0.8 * Double.MAX_VALUE;

    /**
     * assuming a zero-centered mean gaussian kernel, return the bandwidth which minimizes the
     * mean integrated squared error (MISE).
     * NOTE, the method ruleOfThumbBandwidthGaussianKernel() is preferred.
     * &lt;pre&gt;
     *     Silverman 1981, &quot;Kernel Density Estimation Using theFast Fourier Transform&quot;
     * &lt;/pre&gt;
     @param standardDeviation
     @param nSample
     @return
     */
    public static double optimalBandwidthGaussianKernel(double standardDeviation, int nSample) {
<span class="fc" id="L45">        return 1.06 * standardDeviation * Math.pow(nSample, -1./5);</span>
    }

    /**
     * assuming a zero-centered mean gaussian kernel, return Silverman's &quot;rule of thumb&quot; bandwidth.
     * This is considered an improvement over the optimal bandwidth for gaussian kernels.
     * &lt;pre&gt;
     *     Silverman's ‘rule of thumb’, Silverman (1986, page 48, eqn (3.31))).
     *     and
     *     https://rdrr.io/r/stats/bandwidth.html
     &lt;/pre&gt;
     @param standardDeviation
     @param nSample
     @param IQR the interquartile range which is the ordered statistic divided into 4 equal parts, each summed,
     *            then iqr = the 3rd quartile minus the first quartile = sum[3] - sum[0].
     *            see MiscMath0.calcMedianAndIQR()
     @return
     */
    public static double ruleOfThumbBandwidthGaussianKernel(double standardDeviation, double IQR, int nSample) {
<span class="fc" id="L64">        return 0.9 * Math.min(standardDeviation, IQR/1.34) * Math.pow(nSample, -1./5);</span>
    }

    /**
     *
     */
    public static class KDE {

        /**
         * FFT of the histogram of the data.
         u(s) = (1./sqrt(2*pi)) * (1/n) * sum j=1 to n of ( exp(i*s*X_j) ) where i is imaginary
         and n is the length of the data.
         Note that the data are a histogram of the original data.
         &lt;pre&gt;
         reference:
         Silverman, B. W. (1982). Algorithm as 176: Kernel density estimation using the fast Fourier transform. Journal of the Royal Statistical Society. Series C (Applied Statistics), 31(1), 93-99. https://dx.doi.org/10.2307/2347084.
         https://www.jstor.org/stable/2347084#metadata_info_tab_contents
         &lt;/pre&gt;
         */
        public Complex[] u;

        /**
         * the x bins of the histogram of the data used in creating u.
         */
        public double[] hx;

        /**
         * kernel bandwidth
         */
        public double h;

        /**
         * the kde calculated from u and h.
         * kde = inverse FFT(f_n(s))
         *     = inverse FFT( exp(-(0.5) * h^2 * s^2) * u(s)  )
         */
        public double[] kde;
    }

    /**
     * estimate the density by using properties of exponentials (convolution, discrete FFT, fourier pairs ...) 
     to make a faster algorithm.
     &lt;pre&gt;
     reference:
     Silverman, B. W. (1982). Algorithm as 176: Kernel density estimation using the fast Fourier transform. Journal of the Royal Statistical Society. Series C (Applied Statistics), 31(1), 93-99. https://dx.doi.org/10.2307/2347084.
     https://www.jstor.org/stable/2347084#metadata_info_tab_contents
     &lt;/pre&gt;
     calculate the KDE in a fast manner by using discrete FFTs and using a grid of data points
     the kde = f_hat(x) ~ summation over i=1 to n of (K(|| x - X_i ||/h).
     the kernel estimate is a convolution of the data with the kernel.
     naive implementation is O(n^2).
     if the kernel K is chosen to be a Gaussian, one can use a property of exponentials 
     (convolution, discrete FFT, fourier pairs ...) to rewrite:
     exp(x - X_i) = exp(x) * exp(-X_i) (neglecting details)
     also note that the discrete FFT is a summation of exponentials.
     convolution theorem: one can use the pointwise multiplication between the fourier paired functions.
     (Chap 15.5, Boas &quot;Mathematical Methods in the Physical Sciences&quot;)
     convolution to FFT:
     FFT(kde) ~ FFT(K(h*s)) * FFT( hist(X) )
     one can choose s to be the same spatial intervals (=grid) in the histogram
     and in the kernel, to avoid interpolation.  the multiplication is pointwise.
     then inverse FFT of FFT(kde) = kde.
     the runtime complexity is then O(n_s*log(n_s))
     @param x observed data
     @param h bandwidth
     @param histNBins
     @param histMaxBin
     @param histMinBin
     @param histBinWidth
     @return
     */
    public static KDE viaFFTGaussKernel(double[] x, double h, int histNBins, double histBinWidth, double histMinBin,
                                        double histMaxBin) {

        // the histogram length (hist[1].length) is a power of 2 and the range is enlarged by at least 2*3*h
<span class="nc" id="L139">        double[][] hist = createFineHistogram(x, h, histNBins, histBinWidth, histMinBin, histMaxBin);</span>

        //assert(assertHistRange(hist[0], MiscMath0.getMinMax(x), h) == true);

        // normalization is performed by default:
<span class="nc" id="L144">        FFTUtil fft = new FFTUtil();</span>

        // u is the portion that can be re-used on subsequent iterations.  e.g. when iterating
        //   to find minimum bandwidth h.
<span class="nc" id="L148">        Complex[] u = fft.create1DFFTNormalized(hist[1], true);</span>

<span class="nc bnc" id="L150" title="All 2 branches missed.">        assert(u.length == hist[0].length);</span>

<span class="nc" id="L152">        return viaFFTGaussKernel(u, hist[0], h);</span>
    }

    /**
     *
     * estimate the density by using properties of exponentials 
     (convolution, discrete FFT, fourier pairs ...) to make a faster algorithm.
     &lt;pre&gt;
     reference:
     Silverman, B. W. (1982). Algorithm as 176: Kernel density estimation using the fast Fourier transform. Journal of the Royal Statistical Society. Series C (Applied Statistics), 31(1), 93-99. https://dx.doi.org/10.2307/2347084.
     https://www.jstor.org/stable/2347084#metadata_info_tab_contents
     &lt;/pre&gt;
     calculate the KDE in a fast manner by using discrete FFTs and using a grid of data points
     the kde = f_hat(x) ~ summation over i=1 to n of (K(|| x - X_i ||/h).
     the kernel estimate is a convolution of the data with the kernel.
     naive implementation is O(n^2).
     if the kernel K is chosen to be a Gaussian, one can use a property of exponentials to rewrite:
     exp(x - X_i) = exp(x) * exp(-X_i) (neglecting details)
     also note that the discrete FFT is a summation of exponentials.
     convolution theorem: one can use the pointwise multiplication between the fourier paired functions.
     (Chap 15.5, Boas &quot;Mathematical Methods in the Physical Sciences&quot;)
     convolution to FFT:
     FFT(kde) ~ FFT(K(h*s)) * FFT( hist(X) )
     one can choose s to be the same spatial intervals (=grid) in the histogram
     and in the kernel, to avoid interpolation.  the multiplication is pointwise.
     then inverse FFT of FFT(kde) = kde.
     the runtime complexity is then O(n_s*log(n_s))
     @param x data observed
     @param h bandwidth
     @return
     */
    public static KDE viaFFTGaussKernel(double[] x, double h) {

        //TODO: consider using PeriodicFFT from the curvature scale space project instead of FFT
        //     to avoid edge effects.

        // the histogram length (hist[1].length) is a power of 2 and the range is enlarged by at least 2*3*h
<span class="fc" id="L189">        double[][] hist = createFineHistogram(x, h);</span>

        //assert(assertHistRange(hist[0], MiscMath0.getMinMax(x), h) == true);

        // normalization is performed by default:
<span class="fc" id="L194">        FFTUtil fft = new FFTUtil();</span>

        // u is the portion that can be re-used on subsequent iterations.  e.g. when iterating
        //   to find minimum bandwidth h.
<span class="fc" id="L198">        Complex[] u = fft.create1DFFTNormalized(hist[1], true);</span>

<span class="pc bnc" id="L200" title="All 2 branches missed.">        assert(u.length == hist[0].length);</span>

<span class="fc" id="L202">        return viaFFTGaussKernel(u, hist[0], h);</span>

        /*
        summary of the paper:
        note that the f_n(x) is highly inefficient to use directly on a grid of points.
             where f_n(x) = (1./(n*h)) * sum i=1 to n of (K((x - X_i)/h)   EQN (1)

          first, discretize the data to a fine grid
          then use FFT to convolve the data w/ the kernel to calculate .
            *Take FFT of eqn (1):  FFT(f_n(s)) = (sqrt(2*pi)) * FFT(K(h*s))*u(s)
               where u(s) is the fourier transform of the data
               u(s) = (1./sqrt(2*pi)) * (1/n) * sum j=1 to n of ( exp(i*s*X_j) ) where i is imaginary
               ** A discrete approx of u(s) is found by constructing a histogram on a grid of 2^k cells
                  and then apply the FFT to it.
                  (follow Gentelman and Sande as imple. by Monro 1976
               ** The Munroe 1966 FFT takes an array of X(M) of M=2^k real values and returns
                  their discrete fourier transform Y stored with the real parts of Y_0 to Y_{M/2} in
                  locations X(1) to X((M/2)_1) and the imaginary parts of Y_1 to Y_{(M/2)-1} stored
                  M/2 locations above their corresponding real parts.
            *Substitute the fourier transform of the Gaussian Kernel K(h*s)
               FFT(f_n(s)) = exp(-(0.5) * h^2 * s^2) * u(s)   EQN (3)
            *Then f_n(s) = inverse FFT(f_n(s))
             negative values of f_n are set to 0.
               ** note that if several different uses of this algorithm for different h are employed,
               that the discrete FFT has to be calculated only once and can be reused.
               ** The algorithm also avoids exponential underflow by setting
                  FFT(f_n(s)) equal to 0 if 0.5*h*h*s*s is &gt; BIG which is large for the machine.
          The discrete fourier transform should be performed on an interval larger than the interval of
             interest because of wrap around edge conditions.  they recommend enlarging the interval
             by 3*h at each end.  Note that the enlargement is not needed for circular data.
         */
    }

    /**
     * estimate the density of x using a Gaussian Kernel of bandwidth h.
     * note that the grid to which the kernel is applied is also x in this case.
     &lt;pre&gt;
     f_hat(x) ~ (1/n) * summation over i=1 to n of ( (1/h) * K(|| x - X_i ||/h) ).
     double[] kde = iter from j=1-1 to xGrid.length-1 estimating f_hat(xGrid[j]
     reference: Wasserman's &quot;All of Statistics&quot;, eqn (20.21)
     &lt;/pre&gt;
     runtime complexity is O(n^2) where n = x.length.
     @param x data observed
     @param h bandwidth
     @return
     */
    public static KDE viaGaussKernel(double[] x, double h) {
<span class="fc" id="L249">        int n = x.length;</span>
        int i;
<span class="fc" id="L251">        KDE kde = new KDE();</span>
<span class="fc" id="L252">        kde.kde = new double[n];</span>
<span class="fc" id="L253">        GaussianKernel kernel = new GaussianKernel();</span>
<span class="fc" id="L254">        double sum = 0;</span>
<span class="fc bfc" id="L255" title="All 2 branches covered.">        for (i = 0; i &lt; n; ++i) {</span>
<span class="fc" id="L256">            kde.kde[i] = kernel.kernel(x[i], x, h);</span>
<span class="fc" id="L257">            sum += kde.kde[i];</span>
        }
<span class="fc" id="L259">        System.out.printf(&quot;SUM KDE=%.4e\n&quot;, sum);</span>
<span class="fc" id="L260">        kde.hx = Arrays.copyOf(x, x.length);</span>
<span class="fc" id="L261">        kde.h = h;</span>
<span class="fc" id="L262">        kde.u = null;</span>
<span class="fc" id="L263">        return kde;</span>
    }

    /**
     * estimate the density of x using a Gaussian Kernel of bandwidth h.
     * the grid to which the kernel is applied is xGrid in this case.
     &lt;pre&gt;
     f_hat(x) ~ (1/n) * summation over i=1 to n of ( (1/h) * K(|| x - X_i ||/h) ).
     double[] kde = iter from j=1-1 to xGrid.length-1 estimating f_hat(xGrid[j]
     reference: Wasserman's &quot;All of Statistics&quot;, eqn (20.21)
     &lt;/pre&gt;
     runtime complexity is O(n*m) where n = x.length and m=xGrid.length
     @param x data observed
     @param xGrid the grid of data at which to apply the kernel.
     @param h bandwidth
     @return
     */
    public static KDE viaGaussKernel(double[] x, double[] xGrid, double h) {
<span class="fc" id="L281">        int n = xGrid.length;</span>
        int i;
<span class="fc" id="L283">        KDE kde = new KDE();</span>
<span class="fc" id="L284">        kde.kde = new double[n];</span>
<span class="fc" id="L285">        GaussianKernel kernel = new GaussianKernel();</span>
<span class="fc" id="L286">        double sum = 0;</span>
<span class="fc bfc" id="L287" title="All 2 branches covered.">        for (i = 0; i &lt; n; ++i) {</span>
<span class="fc" id="L288">            kde.kde[i] = kernel.kernel(xGrid[i], x, h);</span>
<span class="fc" id="L289">            sum += kde.kde[i];</span>
        }
<span class="fc" id="L291">        System.out.printf(&quot;SUM KDE=%.4e\n&quot;, sum);</span>
<span class="fc" id="L292">        kde.hx = Arrays.copyOf(xGrid, xGrid.length);</span>
<span class="fc" id="L293">        kde.h = h;</span>
<span class="fc" id="L294">        kde.u = null;</span>

<span class="fc" id="L296">        return kde;</span>
    }

    /**
     *
     @param a
     @return
     */
    protected static Complex[] convertToComplex(double[] a) {
<span class="nc" id="L305">        Complex[] c = new Complex[a.length];</span>
<span class="nc bnc" id="L306" title="All 2 branches missed.">        for (int i = 0; i &lt; a.length; ++i) {</span>
<span class="nc" id="L307">            c[i] = new Complex(a[i], 0);</span>
        }
<span class="nc" id="L309">        return c;</span>
    }

    /**
     * calculate a fine resolution histogram for x, for a larger data range than x's.
     * (NOTE that if the data are circular, a method can be created to calculate the histogram
     * using the same data range as x, not larger)
     @param x
     @param h
     @return a 2-dimensional array of the histogram where hist[0] holds the centers of the histogram bins,
     * and hist[1] holds the counts within the bins.
     */
    public static double[][] createFineHistogram(double[] x, double h) {
        // the number of bins need to be a power of 2, and larger than x.length.
        int nBins;
        //if (x.length &lt; 50) {
        //    nBins = x.length;
        //} else {
<span class="fc" id="L327">            nBins = (int) Math.pow(2, Math.ceil(Math.log(x.length * 3) / Math.log(2)));</span>
        //}

        // the power of 10 was inspired by method vbwkde, variable n_dct from documentation:
        //https://user-web.icecube.wisc.edu/~peller/pisa_docs/_modules/pisa/utils/vbwkde.html

        //TODO: improve this with an estimate for available memory of machine
<span class="pc bpc" id="L334" title="1 of 2 branches missed.">        if (nBins &gt; 16384) {</span>
<span class="nc" id="L335">            nBins = 16384;</span>
        }

        // unless the data are circular, the range has to be larger than the range of x in order to
        // avoid wrap around edge conditions
<span class="fc" id="L340">        double[] minMaxX = MiscMath0.getMinMax(x);</span>
<span class="fc" id="L341">        double range = minMaxX[1] - minMaxX[0];</span>
        double dr;
<span class="fc" id="L343">        double he = 3.*h;</span>
<span class="fc bfc" id="L344" title="All 2 branches covered.">        if (0.5 * range &gt; he) {</span>
<span class="fc" id="L345">            dr = 0.5 * range;</span>
        } else {
<span class="fc" id="L347">            dr = he;</span>
        }

<span class="fc" id="L350">        double min = minMaxX[0] - dr;</span>
<span class="fc" id="L351">        double max = minMaxX[1] + dr;</span>

        // nBins = (maxX - minX)/binWidth
<span class="fc" id="L354">        double binWidth = (max - min)/nBins;</span>

<span class="fc" id="L356">        return createFineHistogram(x, h, nBins, binWidth, min, max);</span>
    }

    /**
     * calculate a fine resolution histogram for x, for a larger data range than x's.
     * (NOTE that if the data are circular, a method can be created to calculate the histogram
     * using the same data range as x, not larger)
     @param x
     @param h
     @param nBins
     @param minBin
     @param binWidth
     @param maxBin
     @return a 2-dimensional array of the histogram where hist[0] holds the centers of the histogram bins,
     * and hist[1] holds the counts within the bins.
     */
    protected static double[][] createFineHistogram(double[] x, double h, int nBins, double binWidth,
                                                    double minBin, double maxBin) {

<span class="fc" id="L375">        System.out.printf(&quot;nBins=%d, binWidth=%.4e min=%.4e, max=%.4e\n&quot;, nBins, binWidth, minBin, maxBin);</span>
<span class="fc" id="L376">        System.out.flush();</span>

<span class="fc" id="L378">        double[][] hist = new double[2][];</span>
<span class="fc" id="L379">        hist[0] = new double[nBins];</span>
<span class="fc" id="L380">        hist[1] = new double[nBins];</span>

<span class="fc bfc" id="L382" title="All 2 branches covered.">        for (int i = 0; i &lt; nBins; i++) {</span>
<span class="fc" id="L383">            hist[0][i] = minBin + i*binWidth + (binWidth/2.);</span>
        }

        int bin;
<span class="fc bfc" id="L387" title="All 2 branches covered.">        for (int i = 0; i &lt; x.length; i++) {</span>
<span class="fc" id="L388">            bin = (int) ((x[i] - minBin)/binWidth);</span>
<span class="pc bpc" id="L389" title="2 of 4 branches missed.">            if ((bin &gt; -1) &amp;&amp; (bin &lt; nBins)) {</span>
<span class="fc" id="L390">                hist[1][bin]++;</span>
            }
        }

        // divide by x.length
<span class="fc bfc" id="L395" title="All 2 branches covered.">        for (int i = 0; i &lt; hist[1].length; ++i) {</span>
<span class="fc" id="L396">            hist[1][i] /= ((double)x.length);</span>
        }
<span class="fc" id="L398">        return hist;</span>
    }

    /**
     * calculate a substitute for the fine resolution histogram for x for use in the
     * risk estimator that uses cross-validation.
     @param x
     @return a 2-dimensional array of the histogram where hist[0] holds the centers of the histogram bins,
     * and hist[1] holds the counts within the bins.
     */
    protected static double[] createFineHistogramSubstitute(double[] x) {
<span class="nc" id="L409">        double[] yHist = new double[x.length];</span>
<span class="nc" id="L410">        Arrays.fill(yHist, 1.);</span>
        // divide by x.length
<span class="nc bnc" id="L412" title="All 2 branches missed.">        for (int i = 0; i &lt; yHist.length; ++i) {</span>
<span class="nc" id="L413">            yHist[i] /= x.length;</span>
        }
<span class="nc" id="L415">        return yHist;</span>
    }

    /**
     estimate the density by using properties of exponentials 
     (convolution, discrete FFT, fourier pairs ...) to make a faster algorithm.
     &lt;pre&gt;
           reference:
           Silverman, B. W. (1982). Algorithm as 176: Kernel density estimation using the fast Fourier transform. Journal of the Royal Statistical Society. Series C (Applied Statistics), 31(1), 93-99. https://dx.doi.org/10.2307/2347084.
           https://www.jstor.org/stable/2347084#metadata_info_tab_contents
     &lt;/pre&gt;
     calculate the KDE in a fast manner by using discrete FFTs and using a grid of data points
     the kde = f_hat(x) ~ summation over i=1 to n of (K(|| x - X_i ||/h).
     the kernel estimate is a convolution of the data with the kernel.
     A naive implementation such as the method viaGaussKernel() is O(n^2).
     If the kernel K is chosen to be a Gaussian, one can use a property of exponentials to rewrite:
     exp(x - X_i) = exp(x) * exp(-X_i) (neglecting details)
     also note that the discrete FFT is a summation of exponentials.
     convolution theorem: one can use the pointwise multiplication between the fourier paired functions.
     (Chap 15.5, Boas &quot;Mathematical Methods in the Physical Sciences&quot;)
     convolution to FFT:
     FFT(kde) ~ FFT(K(h*s)) * FFT( hist(X) )
     one can choose s to be the same spatial intervals (=grid) in the histogram
     and in the kernel, to avoid interpolation.  the multiplication is pointwise.
     then inverse FFT of FFT(kde) = kde.
     the runtime complexity is then O(n_s*log(n_s))
     * The Gaussian Kernel with discrete fast fourier transforms is O(s*log(s)).
     @param u the FFT of the histogram of the data.
     @param histBins the x bins of the histogram of the data that were used to create u
     @param h
     @return kernel density estimate
     */
    public static KDE viaFFTGaussKernel(Complex[] u, double[] histBins, double h) {

        //K(x) ≥ 0, ∫K(x)dx = 1, ∫xK(x)dx = 0

        // perform the fourier transform of the Gaussian Kernel K(h*s)
        //    FFT( K(h*s) ) = exp(-(0.5) * h^2 * s^2)
        // s = (x - xTilde[i])/h;  K(s*h)

        // FFT(f_n(s)) = exp(-(0.5) * h^2 * s^2) * u(s)   EQN (3)
        // Then f_n(s) = inverse FFT(f_n(s))
        //     negative values of f_n are set to 0.
        //     note that if different uses of this algorithm for different h are employed,
        //     that the discrete FFT has to be calculated only once and can be reused.
        // The algorithm also avoids exponential underflow by setting
        // FFT(f_n(s)) equal to 0 if 0.5*h*h*s*s is &gt; BIG which is large for the machine.
        int i;
        double zh;
<span class="fc" id="L464">        double c = 1./Math.sqrt(2.*Math.PI);</span>
        // pointwise multiplication
<span class="fc" id="L466">        Complex[] eqn3 = new Complex[histBins.length];</span>
<span class="fc bfc" id="L467" title="All 2 branches covered.">        for (i = 0; i &lt; histBins.length; ++i) {</span>
<span class="fc" id="L468">            zh = histBins[i] * h;</span>
<span class="pc bpc" id="L469" title="1 of 2 branches missed.">            if (zh &lt; BIG) {</span>
<span class="fc" id="L470">                eqn3[i] = u[i].times(c * Math.exp(-0.5 * zh * zh));</span>
            }
        }

<span class="fc" id="L474">        FFTUtil fft = new FFTUtil();</span>

<span class="fc" id="L476">        Complex[] kdeC = fft.create1DFFTNormalized(eqn3, false);</span>
<span class="fc" id="L477">        double[] kd = new double[kdeC.length];</span>
        //double d = 1./(kd.length - 1.);
<span class="fc bfc" id="L479" title="All 2 branches covered.">        for (i = 0; i &lt; kdeC.length; ++i) {</span>
<span class="fc" id="L480">            kd[i] = kdeC[i].abs();</span>
        }

        //
<span class="fc" id="L484">        double sum = sumKDE(kd, histBins[1] - histBins[0]);</span>
<span class="fc" id="L485">        System.out.printf(&quot;h=%.4e sumKDE=%.4e\n&quot;, h,  sum);</span>

<span class="fc" id="L487">        KDE kde = new KDE();</span>
<span class="fc" id="L488">        kde.u = Arrays.copyOf(u, u.length);</span>
<span class="fc" id="L489">        kde.h = h;</span>
<span class="fc" id="L490">        kde.hx = Arrays.copyOf(histBins, histBins.length);</span>
<span class="fc" id="L491">        kde.kde = Arrays.copyOf(kd, kd.length);</span>

<span class="fc" id="L493">        return kde;</span>
    }

    static double sumKDE(double[] kde, double dk) {
<span class="fc" id="L497">        double sum = 0;</span>
<span class="fc bfc" id="L498" title="All 2 branches covered.">        for (int i = 0; i &lt; kde.length; ++i) {</span>
<span class="fc" id="L499">            sum += kde[i];</span>
        }
<span class="fc" id="L501">        return sum;</span>
    }

    /**
     *
     @param histBins
     @param dataMinMax
     @param h
     @return
     */
    protected static boolean assertHistRange(double[] histBins, double[] dataMinMax, double h) {
<span class="nc bnc" id="L512" title="All 2 branches missed.">        if (histBins.length &lt; 3) {</span>
<span class="nc" id="L513">            throw new IllegalArgumentException(&quot;histBins.length must be &gt;= 3&quot;);</span>
        }
<span class="nc" id="L515">        double dataRange = dataMinMax[1] - dataMinMax[0];</span>
<span class="nc" id="L516">        double histBinSize = histBins[1] - histBins[0];</span>
<span class="nc" id="L517">        double histRange = histBins[histBins.length - 1] - histBins[0] + histBinSize;</span>

        // assert histRange + 6h &gt;= dataRange
<span class="nc bnc" id="L520" title="All 2 branches missed.">        return (histRange + 6.*h) &gt;= dataRange;</span>
    }

    /**
     NOTE: this method is replaced by the Silverman FFT approach.

    Wasserman chap 20:
    let X_0,...X_{N-1) denote the observed data which is a sample from f (= probability distribution).
    K is the kernel.
    the KDE estimator f_hat(x) = (1/n) * sum_i=0_to_{N-1} ( (1/h^d) * K((x - X_i)/h)
       where d is the dimensionality

     once the kde is estimated, that is, f_hat(x), the risk can be estimated with Wasserman eqn (20.24)
     J_hat(h) = integral( f_hat^2(x)*dz ) - (2/n) * summation_i=1_to_n( f_hat_{-i)(X_i) }
     where -i denotes &quot;leave one out&quot; of the sample.
    */

    /**
     estimate the KDE for a single value x.
     NOTE that this method is not efficent if used to calculate many x.  one should instead use the FFT method.
     &lt;pre&gt;
     Wasserman chap 20:
     let X_0,...X_{N-1) denote the observed data which is a sample from f (= probability distribution).
     K is the kernel.
     the1-Dimensional  KDE estimator f_hat(x) = (1/n) * sum_i=0_to_{N-1} ( (1/h) * K((x - X_i)/h).
     runtime complexity is O(xTilde.length).
     &lt;/pre&gt;
     @param kernel
     @param x
     @param xTilde the observed data
     @param h the kernel bandwidth
     @return the kde at x
     */
    public static double univariateKernelDensityEstimate(IKernel kernel, double x, double[] xTilde, double h) {
<span class="nc" id="L554">        return kernel.kernel(x, xTilde, h);</span>
    }

    /**
     * a fast cross-validation method which can be used in choosing the bandwidth for the kernel density estimator.
     * the runtime complexity is max( O(n), O(n_s*log_2(ns)))
     *  where n is the data length, and n_s is the number of elements in the data histogram
     * (which is equal to u.length).
     * This method is implemented for 1-D only, but the references (eqn 27) provide a formula for multiple dimensions.
     *
     * NOTE: this method is not ready for use.  I altered the normalization of one of the terms,
     * but the change is a fudge.
     * The test results using the &quot;fudge&quot; look good.
     * This comment will be removed when corrected.
     &lt;pre&gt;
     References:
     Wasserman, &quot;All of Statistics&quot;, eqn (20.25)
     and
     https://www.stat.cmu.edu/~larry/=sml/densityestimation.pdf
     36-708 Statistical Methods for Machine Learning by Larry Wasserman, CMU
     eqn (27) (which is (27)+(28))
     and
     Indirect Cross-validation for Density Estimation
     Olga Y. Savchuk, Jeffrey D. Hart, Simon J. Sheather
     https://doi.org/10.48550/arxiv.0812.0051,
     https://arxiv.org/abs/0812.0051,
     eqn (2).
     &lt;/pre&gt;
     @param u fft of the histogram of the data.
     @param histBins the x axis of the histogram of the data.
     @param h the bandwidth to use
     @return the cross validation score
     */
    public static double crossValidationScore(Complex[] u, double[] histBins, double h) {

        /*
        let K(z, sigma) = normal (gaussian) kernel with mean 0 and variance sigma^2.

        r_hat(h) = (K(0, sqrt(2)*h)/(n-1))
                   + ((n-2)/(n*((n-1)^2))) * summation over i where i!=j of (K(Xi-Xj, sqrt(2)*h))
                   - (2/(n*(n-1))) * summation over i where i!=j of (K(Xi-Xj, h))

        The 2nd and 3rd terms can be estimated using the properties of convolution and discrete FFTs,
        similar to the way the kernel density is estimated using FFTs.
        */

<span class="fc" id="L600">        int n = histBins.length;</span>

        // perform the fourier transform of the Gaussian Kernel K(h*s)
        //    FFT( K(h*s) ) = exp(-(0.5) * h^2 * s^2)
        // s = (x - xTilde[i])/h;  K(s*h)  &lt;== multiply h differently for term1, term2, term3
<span class="fc" id="L605">        double sh = Math.sqrt(2) * h;</span>
<span class="fc" id="L606">        double term1 = 0;</span>

        int i;
        double zh;
        double m;
        // term2: ((n-2)/(n*((n-1)^2))) * summation over i where i!=j of (K(Xi-Xj, sqrt(2)*h))
        //term3: (2/(n*(n-1))) * summation over i where i!=j of (K(Xi-Xj, h))
<span class="fc" id="L613">        double[] f2 = new double[n];</span>
<span class="fc" id="L614">        double[] f3 = new double[n];</span>
<span class="fc bfc" id="L615" title="All 2 branches covered.">        for (i = 0; i &lt; n; ++i) {</span>
<span class="fc" id="L616">            zh = histBins[i] * sh;</span>
<span class="pc bpc" id="L617" title="1 of 2 branches missed.">            if (zh &lt; BIG) {</span>
<span class="fc" id="L618">                m = -0.5 * zh * zh;</span>
<span class="fc" id="L619">                term1 += Math.exp(m);</span>
<span class="fc" id="L620">                f2[i] = u[i].times(Math.exp(m) ).abs();</span>
                // if (m &gt;= 0) {
            }
<span class="fc" id="L623">            zh = histBins[i] * h;</span>
<span class="pc bpc" id="L624" title="1 of 2 branches missed.">            if (zh &lt; BIG) {</span>
<span class="fc" id="L625">                f3[i] = u[i].times(Math.exp(-0.5 * zh * zh)).abs();</span>
                // if (m &gt;= 0) {
            }
        }
<span class="fc" id="L629">        term1 /= (n - 1.);</span>

<span class="fc" id="L631">        FFTUtil fft = new FFTUtil();</span>
<span class="fc" id="L632">        Complex[] t2 = fft.create1DFFTNormalized(f2, false);</span>
<span class="fc" id="L633">        Complex[] t3 = fft.create1DFFTNormalized(f3, false);</span>

<span class="fc" id="L635">        double term2 = 0;</span>
<span class="fc" id="L636">        double term3 = 0.;</span>
<span class="fc bfc" id="L637" title="All 2 branches covered.">        for (i = 0; i &lt; n; ++i) {</span>
<span class="fc" id="L638">            term2 += t2[i].abs();</span>
<span class="fc" id="L639">            term3 += t3[i].abs();</span>
        }

<span class="fc" id="L642">        term2 *= ((n-2.)/(n*(n-1.)*(n-1.)));</span>
<span class="fc" id="L643">        term3 *= (2./(n*(n-1.)));</span>

        // there is an error in my implementation
<span class="fc" id="L646">        double r = term1 + term2 - term3;</span>

        // fudge, to be removed when the bug is found
<span class="fc" id="L649">        r = term1/(n*n) + term2 - term3;</span>

<span class="fc" id="L651">        System.out.printf(&quot;h=%.4e terms=%.4e %.4e %.4e  r=%.4e\n&quot;, h, term1, term2, term3, r);</span>

<span class="fc" id="L653">        return r;</span>

        /*
        try again, but with the Wasserman eqn (20.25)

        r_hat(h) ~ (2/(n*h)) * K(0)
                    + (1/(h*n*n)) * sum_i( sum_j(
                         K_ast((X_i-X_j)/h) ))

        where
        K_2(z) = integral( K(z-y)*K(y)*dy )
        K_ast(x) = K_2(x) - 2*K(x)

        z = (X_i-X_j)/h;
        K_ast((X_i-X_j)/h) = K_2(z) - 2*K(z) = N(0,2) - 2*K(z)
                           = integral( K(z-y)*K(y)*dy ) - 2*K(z)

        r_hat(h) ~ (2/(n*h)) * N(0,1)
                 + (1/(h*n*n)) * sum_i( sum_j(
                     integral( K(z-y)*K(y)*dy ) - 2*K(z)
                 ))
        */
    }

    /**
     * calculate the risk estimator for the &quot;leave-one-out&quot; method of cross validation.
     * This method can be used to select a kde bandwidth by minimizing the risk estimator for a range
     * of bandwidths.  It is a data based method as the true probability distribution is unknown.
     &lt;pre&gt;
     see eqn (20.24) of Wasserman's &quot;All of Statistics&quot;
     see eqn (26) of
     https://www.stat.cmu.edu/~larry/=sml/densityestimation.pdf
     36-708 Statistical Methods for Machine Learning by Larry Wasserman, CMU
     &lt;/pre&gt;
     @return
     */
    static double riskEstimatorLeaveOneOut() {

        // r_hat(h) = integral( (p_hat(x))^2*dx - (2/n) * summation_i=1_to_n( p_hat(X_i) )
        //    the 3rd compoonent on the right hand side is dropped as it's a constant (and so cancels out in comparisons
        //    for bandwidth selection) and it is nearly negligible as n increases.
        //
        //     for the &quot;leave-one-out&quot; algorithm, p_hat is the density estimator after removing
        //        the &quot;i-th&quot; observation.
        //     for the &quot;data-splitting&quot; algorithm,
        //        X_i is split into half randomly, and that instead of the entire X_i is used
        //        in the summation above.
        //        Note that splitting in half is V-fold or k-fold of 2, but a larger number can be used instead.

<span class="nc" id="L702">        throw new UnsupportedOperationException(&quot;not yet implemented&quot;);</span>
    }

    /**
     * calculate the risk estimator for the &quot;data-splitting&quot; V-fold or k-fold method of cross validation.
     * This method can be used to select a kde bandwidth by minimizing the risk estimator for a range
     * of bandwidths.  It is a data based method as the true probability distribution is unknown.
     &lt;pre&gt;
     see eqn (20.24) of Wasserman's &quot;All of Statistics&quot;.
     see eqn (26) of
     https://www.stat.cmu.edu/~larry/=sml/densityestimation.pdf
     36-708 Statistical Methods for Machine Learning by Larry Wasserman, CMU
     &lt;/pre&gt;
     @return
     */
    static double riskEstimatorDataSplitting() {

        // r_hat(h) = integral( (p_hat(x))^2*dx - (2/n) * summation_i=1_to_n( p_hat(X_i) )
        //    the 3rd compoonent on the right hand side is dropped as it's a constant (and so cancels out in comparisons
        //    for bandwidth selection) and it is nearly negligible as n increases.
        //
        //     for the &quot;leave-one-out&quot; algorithm, p_hat is the density estimator after removing
        //        the &quot;i-th&quot; observation.
        //     for the &quot;data-splitting&quot; algorithm,
        //        X_i is split into half randomly, and that instead of the entire X_i is used
        //        in the summation above.
        //        Note that splitting in half is V-fold or k-fold of 2, but a larger number can be used instead.

<span class="nc" id="L730">        throw new UnsupportedOperationException(&quot;not yet implemented&quot;);</span>
    }

    /**
     * calculate the risk estimator for the &quot;leave-one-out&quot; method of cross validation.
     * This method can be used to select a kde bandwidth by minimizing the risk estimator for a range
     * of bandwidths.  It is a data based method as the true probability distribution is unknown.
     &lt;pre&gt;
     see eqn (27), (28) of
     https://www.stat.cmu.edu/~larry/=sml/densityestimation.pdf
     36-708 Statistical Methods for Machine Learning by Larry Wasserman, CMU.
     see eqn (20.24) of Wasserman's &quot;All of Statistics&quot;
     &lt;/pre&gt;
     @return
     */
    static double riskEstimatorGaussianKernel() {

        // r_hat(h) = integral( (p_hat(x))^2*dx - (2/n) * summation_i=1_to_n( p_hat(X_i) )
        //    the 3rd compoonent on the right hand side is dropped as it's a constant (and so cancels out in comparisons
        //    for bandwidth selection) and it is nearly negligible as n increases.
        //
        //     for the &quot;leave-one-out&quot; algorithm, p_hat is the density estimator after removing
        //        the &quot;i-th&quot; observation.
        //     for the &quot;data-splitting&quot; algorithm,
        //        X_i is split into half randomly, and that instead of the entire X_i is used
        //        in the summation above.
        //        Note that splitting in half is V-fold or k-fold of 2, but a larger number can be used instead.

<span class="nc" id="L758">        throw new UnsupportedOperationException(&quot;not yet implemented&quot;);</span>
    }

    static double sumHistogram(double[][] hist) {
<span class="fc" id="L762">        double sum = 0;</span>
<span class="fc" id="L763">        double dh = hist[0][1] - hist[0][0];</span>
<span class="fc bfc" id="L764" title="All 2 branches covered.">        for (int i = 0; i &lt; hist[0].length; ++i) {</span>
<span class="fc" id="L765">            sum += (hist[1][i]);</span>
        }
<span class="fc" id="L767">        return sum;</span>
    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>
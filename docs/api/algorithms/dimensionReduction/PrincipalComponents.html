<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (17) on Mon Nov 11 09:31:09 PST 2024 -->
<title>PrincipalComponents</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2024-11-11">
<meta name="description" content="declaration: package: algorithms.dimensionReduction, class: PrincipalComponents">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
<script type="text/javascript" src="../../script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var evenRowColor = "even-row-color";
var oddRowColor = "odd-row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top">
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-all.html">Index</a></li>
<li><a href="../../help-doc.html#class">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div>
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li><a href="#nested-class-summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor-summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method-summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor-detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search-input">SEARCH:</label>
<input type="text" id="search-input" value="search" disabled="disabled">
<input type="reset" id="reset-button" value="reset" disabled="disabled">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">algorithms.dimensionReduction</a></div>
<h1 title="Class PrincipalComponents" class="title">Class PrincipalComponents</h1>
</div>
<div class="inheritance" title="Inheritance Tree"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">java.lang.Object</a>
<div class="inheritance">algorithms.dimensionReduction.PrincipalComponents</div>
</div>
<section class="class-description" id="class-description">
<hr>
<div class="type-signature"><span class="modifiers">public class </span><span class="element-name type-name-label">PrincipalComponents</span>
<span class="extends-implements">extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></span></div>
<div class="block">find the principal components, that is, the minimal residual variance bases
 of vectors of samples following G. Strang's SVD in machine learning in
 http://www.cs.toronto.edu/~jepson/csc420/
 
 from wikipedia:
 The principal components of a collection of points in a real coordinate space 
 are a sequence of p unit vectors, where the i-th vector is the direction of 
 a line that best fits the data while being orthogonal to the first i-1 vectors. 
 Here, a best-fitting line is defined as one that minimizes the average 
 squared distance from the points to the line. These directions constitute an 
 orthonormal basis in which different individual dimensions of the data are 
 linearly uncorrelated. Principal component analysis (PCA) is the process of 
 computing the principal components and using them to perform a change of basis 
 on the data, sometimes using only the first few principal components and 
 ignoring the rest.
 
 from wikipedia:
 
 PCA is closely related to Fisher's Discriminant Anaylsisi a.k.a. 
 Linear Discriminant analysis and factor analysis in that they both look for 
 linear combinations of variables which best explain the data.[4] 
 LDA explicitly attempts to model the difference between the classes of data. 
 PCA, in contrast, does not take into account any difference in class, 
 and factor analysis builds the feature combinations based on differences 
 rather than similarities.
 NOTE:  Fisher's original article[1] actually describes a slightly different 
 discriminant, which does not make some of the assumptions of LDA such as 
 normally distributed classes or equal class covariances.
 
 LDA is closely related to analysis of variance (ANOVA) and regression analysis, 
 which also attempt to express one dependent variable as a linear combination 
 of other features or measurements.[1][2] However, ANOVA uses categorical 
 independent variables and a continuous dependent variable, whereas 
 discriminant analysis has continuous independent variables and a categorical 
 dependent variable (i.e. the class label).[3] Logistic regression and 
 probit regression are more similar to LDA than ANOVA is, as they also 
 explain a categorical variable by the values of continuous independent 
 variables. These other methods are preferable in applications where it is 
 not reasonable to assume that the independent variables are normally 
 distributed, which is a fundamental assumption of the LDA method.</div>
<dl class="notes">
<dt>Author:</dt>
<dd>nichole</dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<li>
<section class="nested-class-summary" id="nested-class-summary">
<h2>Nested Class Summary</h2>
<div class="caption"><span>Nested Classes</span></div>
<div class="summary-table three-column-summary">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Class</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color"><code>static class&nbsp;</code></div>
<div class="col-second even-row-color"><code><a href="PrincipalComponents.PCAStats.html" class="type-name-link" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a></code></div>
<div class="col-last even-row-color">&nbsp;</div>
</div>
</section>
</li>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<li>
<section class="constructor-summary" id="constructor-summary">
<h2>Constructor Summary</h2>
<div class="caption"><span>Constructors</span></div>
<div class="summary-table two-column-summary">
<div class="table-header col-first">Constructor</div>
<div class="table-header col-last">Description</div>
<div class="col-constructor-name even-row-color"><code><a href="#%3Cinit%3E()" class="member-name-link">PrincipalComponents</a>()</code></div>
<div class="col-last even-row-color">&nbsp;</div>
</div>
</section>
</li>
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method-summary">
<h2>Method Summary</h2>
<div id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="method-summary-table-tab0" role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table', 3)" class="active-table-tab">All Methods</button><button id="method-summary-table-tab1" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab1', 3)" class="table-tab">Static Methods</button><button id="method-summary-table-tab4" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab4', 3)" class="table-tab">Concrete Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel">
<div class="summary-table three-column-summary" aria-labelledby="method-summary-table-tab0">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Method</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#calcPrincipalComponents(double%5B%5D%5B%5D,boolean,double)" class="member-name-link">calcPrincipalComponents</a><wbr>(double[][]&nbsp;x,
 boolean&nbsp;useEVProp,
 double&nbsp;prop)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">
<div class="block">calculate the principal components of the unit standardized data x
 using Singular Value Decomposition or CUR Decomposition.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#calcPrincipalComponents(double%5B%5D%5B%5D,int)" class="member-name-link">calcPrincipalComponents</a><wbr>(double[][]&nbsp;x,
 int&nbsp;nComponents)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">
<div class="block">calculate the principal components of the unit standardized data x
 using Singular Value Decomposition.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#calcPrincipalComponents(double%5B%5D%5B%5D,int,boolean)" class="member-name-link">calcPrincipalComponents</a><wbr>(double[][]&nbsp;x,
 int&nbsp;nComponents,
 boolean&nbsp;useCUR)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">
<div class="block">calculate the principal components of the unit standardized data x
 using Singular Value Decomposition or CUR Decomposition.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static double[][]</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#reconstruct(double%5B%5D,algorithms.dimensionReduction.PrincipalComponents.PCAStats)" class="member-name-link">reconstruct</a><wbr>(double[]&nbsp;m,
 <a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a>&nbsp;stats)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">
<div class="block">reconstruct an image from x, given principal directions.</div>
</div>
</div>
</div>
</div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-java.lang.Object">Methods inherited from class&nbsp;java.lang.<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></h3>
<code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#clone()" title="class or interface in java.lang" class="external-link">clone</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#equals(java.lang.Object)" title="class or interface in java.lang" class="external-link">equals</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#finalize()" title="class or interface in java.lang" class="external-link">finalize</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#getClass()" title="class or interface in java.lang" class="external-link">getClass</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#hashCode()" title="class or interface in java.lang" class="external-link">hashCode</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#notify()" title="class or interface in java.lang" class="external-link">notify</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#notifyAll()" title="class or interface in java.lang" class="external-link">notifyAll</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#toString()" title="class or interface in java.lang" class="external-link">toString</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait()" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait(long)" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait(long,int)" title="class or interface in java.lang" class="external-link">wait</a></code></div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<li>
<section class="constructor-details" id="constructor-detail">
<h2>Constructor Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="&lt;init&gt;()">
<h3>PrincipalComponents</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="element-name">PrincipalComponents</span>()</div>
</section>
</li>
</ul>
</section>
</li>
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method-detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="calcPrincipalComponents(double[][],int)">
<h3>calcPrincipalComponents</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a></span>&nbsp;<span class="element-name">calcPrincipalComponents</span><wbr><span class="parameters">(double[][]&nbsp;x,
 int&nbsp;nComponents)</span>
                                                            throws <span class="exceptions">no.uib.cipr.matrix.NotConvergedException</span></div>
<div class="block">calculate the principal components of the unit standardized data x
 using Singular Value Decomposition.
 NOTE: the data need to be zero centered first.

     <pre>
     the method follows:
     http://www.cs.toronto.edu/~jepson/csc420/
     combined with the book by Strang "Introduction to Linear Algebra"
     also useful:
     https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca
     and https://online.stat.psu.edu/stat505/book/export/html/670 for testing results,
     </pre>
     <pre>
     NOTE:
     variance-covariance(standardized data) == correlation(unstandardized data) == correlation(zero mean centered data).
     therefore, pca using the standardized data == pca using the correlation matrix.
     Also, the eigen of cov(standardized) == eigen of cor(unstandardized).
     </pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>x</code> - is a 2-dimensional array of k vectors of length n in format
    double[n][k].  n is the number of samples, and k is the number of
    variables, a.k.a. dimensions.
    x should be zero-centered (mean=0) OR standardized to unit normalization (which is mean=0, stdev=1).
    If the variance and scale of the variables are different, then unit standard normalization should be used.
     Note that using "zero mean centered" x is equivalent to pca on the covariance matrix,
        while using "unit standard norm: x is equivalent to pca on the correlation matrix.</dd>
<dd><code>nComponents</code> - the number of principal components to return.</dd>
<dt>Returns:</dt>
<dd>the principal axes, the principal components, and
     a few statistics of the CUR decomposition of A, up to the
     nComponents dimension.  Note that if the rank of the A is
     less than nComponents, then only the number of components as rank is returned.</dd>
<dt>Throws:</dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="calcPrincipalComponents(double[][],boolean,double)">
<h3>calcPrincipalComponents</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a></span>&nbsp;<span class="element-name">calcPrincipalComponents</span><wbr><span class="parameters">(double[][]&nbsp;x,
 boolean&nbsp;useEVProp,
 double&nbsp;prop)</span>
                                                            throws <span class="exceptions">no.uib.cipr.matrix.NotConvergedException</span></div>
<div class="block">calculate the principal components of the unit standardized data x
 using Singular Value Decomposition or CUR Decomposition.
 NOTE: the data need to be zero centered first.

     <pre>
     the method follows:
     http://www.cs.toronto.edu/~jepson/csc420/
     combined with the book by Strang "Introduction to Linear Algebra"
     and the book by Leskovec, Rajaraman, and Ullman "Mining of Massive Datasets".
     also useful:
     https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca
     and https://online.stat.psu.edu/stat505/book/export/html/670
     </pre>
     <pre>
     NOTE:
     variance-covariance(standardized data) == correlation(unstandardized data) == correlation(zero mean centered data).
     therefore, pca using the standardized data == pca using the correlation matrix.
     Also, the eigen of cov(standardized) == eigen of cor(unstandardized).
     </pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>x</code> - is a 2-dimensional array of k vectors of length n in format
    double[n][k].  n is the number of samples, and k is the number of
    variables, a.k.a. dimensions.
    x should be zero-centered (mean=0) OR standardized to unit normalization (which is mean=0, stdev=1).
    If the variance and scale of the variables are different, then unit standard normalization should be used.
    Note that using "zero mean centered" x is equivalent to pca on the covariance matrix,
        while using "unit standard norm: x is equivalent to pca on the correlation matrix.</dd>
<dd><code>useEVProp</code> - if true, uses the cumulative fraction of eigenvalues in combination with the
     proportion prop to determine the number of principal components to calculate, else if false,
     uses the cumulative fraction of singular values in combination with the proportaion prop to
     determine the number of principal components.  Note that the closest cumulative fraction to prop is used
     rather than meeting and possibly exceeding prop.
     e.g.  prop of 80% to 90% w/ useEVProp = true.</dd>
<dd><code>prop</code> - </dd>
<dt>Returns:</dt>
<dd>the principal axes, the principal components, and
     a few statistics of the CUR decomposition of A, up to the
     nComponents dimension.  Note that if the rank of the A is
     less than nComponents, then only the number of components as rank is returned.</dd>
<dt>Throws:</dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="calcPrincipalComponents(double[][],int,boolean)">
<h3>calcPrincipalComponents</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a></span>&nbsp;<span class="element-name">calcPrincipalComponents</span><wbr><span class="parameters">(double[][]&nbsp;x,
 int&nbsp;nComponents,
 boolean&nbsp;useCUR)</span>
                                                            throws <span class="exceptions">no.uib.cipr.matrix.NotConvergedException</span></div>
<div class="block">calculate the principal components of the unit standardized data x
 using Singular Value Decomposition or CUR Decomposition.
 NOTE: the data need to be zero centered first.

     <pre>
     the method follows:
     http://www.cs.toronto.edu/~jepson/csc420/
     combined with the book by Strang "Introduction to Linear Algebra"
     and the book by Leskovec, Rajaraman, and Ullman "Mining of Massive Datasets".
     also useful:
     https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca
     and https://online.stat.psu.edu/stat505/book/export/html/670
     </pre>
     <pre>
     NOTE:
     variance-covariance(standardized data) == correlation(unstandardized data) == correlation(zero mean centered data).
     therefore, pca using the standardized data == pca using the correlation matrix.
     Also, the eigen of cov(standardized) == eigen of cor(unstandardized).
     </pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>x</code> - is a 2-dimensional array of k vectors of length n in format
    double[n][k].  n is the number of samples, and k is the number of
    variables, a.k.a. dimensions.
    x should be zero-centered (mean=0) OR standardized to unit normalization (which is mean=0, stdev=1).
    If the variance and scale of the variables are different, then unit standard normalization should be used.
         Note that using "zero mean centered" x is equivalent to pca on the covariance matrix,
      *        while using "unit standard norm: x is equivalent to pca on the correlation matrix.</dd>
<dd><code>nComponents</code> - the number of principal components to return.</dd>
<dd><code>useCUR</code> - if true, uses CUR decomposition instead of Singular Value Decomposition.  CUR decomposition
     is useful for very large datasets.</dd>
<dt>Returns:</dt>
<dd>the principal axes, the principal components, and
     a few statistics of the CUR decomposition of A, up to the
     nComponents dimension.  Note that if the rank of the A is
     less than nComponents, then only the number of components as rank is returned.</dd>
<dt>Throws:</dt>
<dd><code>no.uib.cipr.matrix.NotConvergedException</code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reconstruct(double[],algorithms.dimensionReduction.PrincipalComponents.PCAStats)">
<h3>reconstruct</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type">double[][]</span>&nbsp;<span class="element-name">reconstruct</span><wbr><span class="parameters">(double[]&nbsp;m,
 <a href="PrincipalComponents.PCAStats.html" title="class in algorithms.dimensionReduction">PrincipalComponents.PCAStats</a>&nbsp;stats)</span></div>
<div class="block">reconstruct an image from x, given principal directions.
 from http://www.cs.toronto.edu/~jepson/csc420/
 combined with the book by Strang "Introduction to Linear Algebra" 
 and the book by Leskovec, Rajaraman, and Ullman "Mining of Massive Datasets"
 <pre>
     ⃗r(⃗a_0) = m⃗_s + U_p * ⃗a 
         where U_p is the principalDirections matrix,
         where m_s is the sample x mean,
         where a_0 is
            a_0 = arg min_{a} ||⃗x − (m⃗_s + U _p * a)||^2
 </pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>m</code> - the means of each column of x (used in the zero-correction of x).  the length is k
          where k is the number of columns in x before
          dimension reduction.</dd>
<dd><code>stats</code> - the statistics of the principal axes derived from
 SVD of the covariance of the training data.</dd>
<dt>Returns:</dt>
<dd>the reconstruction of x.  size is [n x k]</dd>
</dl>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
</div>
</div>
</body>
</html>
